{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce74b38",
   "metadata": {},
   "source": [
    "# Predicting Heart Disease\n",
    "#### Panoramica\n",
    "- Obiettivo: Predict the likelihood of heart disease.\n",
    "- Tipo di Competizione: Tabulare\n",
    "- Metrica di Valutazione: Roc Auc Score\n",
    "#### \n",
    "| Caratteristica | Descrizione |\n",
    "| :--- | :---: |\n",
    "| id | Identificativo unico per ogni paziente nel dataset. |\n",
    "| Age | Et√† del paziente espressa in anni. |\n",
    "| Sex | Genere del paziente (generalmente 1 = Maschio, 0 = Femmina). |\n",
    "| Chest pain type | Tipologia di dolore toracico (da 1 a 4: anginoso tipico, atipico, non anginoso, asintomatico). |\n",
    "| BP | Pressione sanguigna a riposo (espressa in mm Hg al momento dell'ammissione). |\n",
    "| Cholesterol | Livello di colesterolo sierico espresso in mg/dl. |\n",
    "| FBS over 120 | Zucchero nel sangue a digiuno > 120 mg/dl (1 = Vero; 0 = Falso). |\n",
    "| EKG results | Risultati dell'elettrocardiogramma a riposo (valori 0, 1, 2 basati su anomalie). |\n",
    "| Max HR | Frequenza cardiaca massima raggiunta durante il test da sforzo. |\n",
    "| Exercise angina | Angina indotta dall'esercizio fisico (1 = S√¨; 0 = No). |\n",
    "| ST depression | Depressione del segmento ST indotta dall'esercizio rispetto al riposo. |\n",
    "| Slope of ST | Pendenza del segmento ST nel picco dell'esercizio (1: crescente, 2: piatto, 3: decrescente). |\n",
    "| Number of vessels fluro | Numero di vasi principali (0-3) colorati mediante fluoroscopia. |\n",
    "| Thallium | Risultato del test al tallio (3 = normale; 6 = difetto fisso; 7 = difetto reversibile). |\n",
    "| Heart Disease | Target: Presenza (1 o >0) o assenza (0) di patologia cardiaca. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5eba2",
   "metadata": {},
   "source": [
    "## 0. Environment & Data Fetching\n",
    "(Configurazione, rilevamento ambiente, caricamento dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37562535",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0. Environment & Data Fetching (Universal Setup)\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "COMPETITION_NAME = 'playground-series-s6e2' \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if os.getenv('KAGGLE_KERNEL_RUN_TYPE'):\n",
    "    print(f\"‚òÅÔ∏è  Rilevato ambiente Kaggle.\")\n",
    "    \n",
    "    PATH = f'/kaggle/input/{COMPETITION_NAME}'\n",
    "    \n",
    "else:\n",
    "    print(\"üíª Rilevato ambiente Locale.\")\n",
    "    PATH = '.' \n",
    "    \n",
    "    import zipfile\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    \n",
    "    if not os.path.exists(f'{PATH}/train.csv'):\n",
    "        print(f\"‚¨áÔ∏è  File non trovati. Avvio download per: {COMPETITION_NAME}...\")\n",
    "        \n",
    "        try:\n",
    "            api = KaggleApi()\n",
    "            api.authenticate() \n",
    "            api.competition_download_files(COMPETITION_NAME, path=PATH)\n",
    "            \n",
    "            print(\"üì¶ Estrazione in corso...\")\n",
    "            with zipfile.ZipFile(f'{PATH}/{COMPETITION_NAME}.zip', 'r') as zip_ref:\n",
    "                zip_ref.extractall(PATH)\n",
    "            print(\"‚úÖ Download ed estrazione completati!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Errore nel download (Verifica il file kaggle.json): {e}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Dati gi√† presenti in locale.\")\n",
    "\n",
    "try:\n",
    "    train = pd.read_csv(f'{PATH}/train.csv')\n",
    "    test = pd.read_csv(f'{PATH}/test.csv')\n",
    "    sample_sub = pd.read_csv(f'{PATH}/sample_submission.csv')\n",
    "    \n",
    "    print(f\"\\n--- Data Loaded Successfully ---\")\n",
    "    print(f\"Train shape: {train.shape}\")\n",
    "    print(f\"Test shape:  {test.shape}\")\n",
    "    print(f\"Sub shape:   {sample_sub.shape}\")\n",
    "\n",
    "    display(train.head(3)) \n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\n‚ùå ERRORE CRITICO: Dataset non trovato!\")\n",
    "    print(f\"Percorso cercato: {PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a8315e",
   "metadata": {},
   "source": [
    "## 1. Imports & Global Configuration\n",
    "(Importazione librerie, configurazione Plotly e Seed per la riproducibilit√†)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Visualization \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-Learn Preprocessing & Validation\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# Scikit-Learn Metrics\n",
    "from sklearn.metrics import roc_auc_score, auc, accuracy_score, confusion_matrix, classification_report\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore') \n",
    "pio.templates.default = \"plotly_white\" \n",
    "\n",
    "# Global Constants\n",
    "RANDOM_STATE = 42 \n",
    "N_FOLDS = 10 \n",
    "\n",
    "print(\"‚úÖ Librerie importate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8a031",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "(Analisi distribuzioni, correlazioni, outlier, visualizzazione target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.X Data Cleaning & Target Fix\n",
    "\n",
    "print(\"\\n--- DIAGNOSTICA PRE-FIX ---\")\n",
    "print(f\"Valori unici in 'Heart Disease': {train['Heart Disease'].unique()}\")\n",
    "print(f\"Tipo di dato attuale: {train['Heart Disease'].dtype}\")\n",
    "\n",
    "# FIX: Se il tipo √® object (stringa) o contiene valori testuali, li riconvertiamo\n",
    "if train['Heart Disease'].dtype == 'object' or 'Absence' in train['Heart Disease'].values:\n",
    "    print(\"‚ö†Ô∏è Rilevate stringhe nel Target. Conversione in numeri (0/1)...\")\n",
    "    \n",
    "    mapping_fix = {\n",
    "        'Absence': 0, \n",
    "        'Presence': 1\n",
    "    }\n",
    "    \n",
    "    train['Heart Disease'] = train['Heart Disease'].map(mapping_fix)\n",
    "\n",
    "train['Heart Disease'] = pd.to_numeric(train['Heart Disease'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "print(\"\\n--- DIAGNOSTICA POST-FIX ---\")\n",
    "print(f\"‚úÖ Valori unici finali: {train['Heart Disease'].unique()}\")\n",
    "print(f\"‚úÖ Tipo di dato finale: {train['Heart Disease'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.1 Data Health Check ---\n",
    "\n",
    "print(f\"Valori mancanti nel Train: {train.isnull().sum().sum()}\")\n",
    "print(f\"Valori mancanti nel Test:  {test.isnull().sum().sum()}\")\n",
    "\n",
    "duplicates = train.duplicated().sum()\n",
    "if duplicates > 0:\n",
    "    print(f\"‚ö†Ô∏è Trovati {duplicates} duplicati nel training set. Considera di rimuoverli.\")\n",
    "else:\n",
    "    print(\"‚úÖ Nessun duplicato trovato.\")\n",
    "\n",
    "# --- 2.2 Target Distribution ---\n",
    "target_counts = train['Heart Disease'].value_counts().reset_index()\n",
    "target_counts.columns = ['Heart Disease', 'Count']\n",
    "target_counts['Label'] = target_counts['Heart Disease'].astype(int).map({0: 'No Disease', 1: 'Disease'})\n",
    "\n",
    "fig = px.pie(target_counts, \n",
    "             values='Count', \n",
    "             names='Label', \n",
    "             title='Distribuzione Target: Presenza vs Assenza Malattia Cardiaca',\n",
    "             color='Label',\n",
    "             color_discrete_map={'No Disease':'#66b3ff', 'Disease':'#ff9999'},\n",
    "             hole=0.4) \n",
    "\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.3 Numerical Features Distribution ---\n",
    "\n",
    "numerical_cols = ['Age', 'BP', 'Cholesterol', 'Max HR', 'ST depression', 'Number of vessels fluro']\n",
    "\n",
    "for col in numerical_cols:\n",
    "    fig = px.histogram(train, \n",
    "                       x=col, \n",
    "                       color='Heart Disease',\n",
    "                       marginal=\"box\", \n",
    "                       title=f'Distribuzione di {col} rispetto al Target',\n",
    "                       color_discrete_map={0:'#66b3ff', 1:'#ff9999'},\n",
    "                       opacity=0.7,\n",
    "                       barmode='overlay') \n",
    "    \n",
    "    fig.update_layout(bargap=0.1)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5181ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.4 Categorical Features Analysis ---\n",
    "\n",
    "cat_cols = ['Sex', 'Chest pain type', 'FBS over 120', 'EKG results', \n",
    "            'Exercise angina', 'Slope of ST', 'Thallium']\n",
    "\n",
    "for col in cat_cols:\n",
    "    df_grouped = train.groupby(col)['Heart Disease'].value_counts(normalize=True).rename('percentage').reset_index()\n",
    "    df_grouped['percentage'] = df_grouped['percentage'] * 100\n",
    "    df_grouped['Heart Disease'] = df_grouped['Heart Disease'].astype(int).map({0: 'Absence', 1: 'Presence'})\n",
    "    \n",
    "    df_grouped = df_grouped.sort_values(by=[col, 'Heart Disease'])\n",
    "\n",
    "    fig = px.bar(df_grouped, \n",
    "                 x=col, \n",
    "                 y='percentage', \n",
    "                 color='Heart Disease',\n",
    "                 barmode='group',\n",
    "                 title=f'Incidenza Malattia per: {col}',\n",
    "                 color_discrete_map={'Absence':'#66b3ff', 'Presence':'#ff9999'},\n",
    "                 text_auto='.1f') \n",
    "    \n",
    "    fig.update_layout(yaxis_title=\"Percentuale (%)\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b7932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.5 Correlation Matrix ---\n",
    "\n",
    "corr_matrix = train.corr(numeric_only=True)\n",
    "\n",
    "fig = px.imshow(corr_matrix, \n",
    "                text_auto='.2f', \n",
    "                aspect=\"auto\",\n",
    "                color_continuous_scale='RdBu_r', \n",
    "                title='Matrice di Correlazione (Heatmap)')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb5014",
   "metadata": {},
   "source": [
    "Sex (Bar Chart)\n",
    "Il \"Gender Gap\": C'√® una differenza enorme.\n",
    "- Donne (0): Solo il 17.9% ha la malattia. Essere donna √® un forte fattore protettivo in questo dataset.\n",
    "- Uomini (1): Il rischio sale al 55.6%. Pi√π della met√† degli uomini nel dataset presenta la patologia.\n",
    "\n",
    "Chest Pain Type (Bar Chart)\n",
    "Il Paradosso dell'Asintomatico:\n",
    "- I tipi 1, 2 e 3 hanno prevalenza di \"Sani\" (Barre blu alte).\n",
    "- Il Tipo 4 (Asintomatico) √® critico: quasi il 70% (69.7%) dei pazienti in questa categoria √® malato. Se il modello vede \"Type 4\", alzer√† drasticamente la probabilit√† di rischio.\n",
    "\n",
    "- Exercise Angina: Questa √® una Red Flag. Se c'√® angina durante lo sforzo (1), la probabilit√† di malattia schizza verso l'alto (barra turchese molto ridotta rispetto alla controparte).\n",
    "\n",
    "ST Depression (Box Plot)\n",
    "Il marcatore dell'ischemia:\n",
    "- I sani sono concentrati sullo 0.\n",
    "- Appena il valore sale sopra lo 0.5 o 1.0, la probabilit√† di malattia domina. La \"coda\" rossa verso destra √® un segnale inequivocabile.\n",
    "\n",
    "- Thallium: Il valore 3 sembra \"sicuro\" (Normal), mentre 7 (Reversibile) e 6 (Fisso) portano con s√© un alto tasso di positivit√†.\n",
    "\n",
    "Max HR (Box Plot + Histogram)\n",
    "La prova da sforzo:\n",
    "- Si nota una separazione netta. I pazienti sani (Blu) riescono a spingere il cuore a frequenze molto pi√π alte (mediana intorno a 160 bpm).\n",
    "- I pazienti malati (Rosso) si fermano prima (mediana intorno a 130-140 bpm).\n",
    "\n",
    "Number of Vessels Fluro (Bar Chart)\n",
    "Gradino di rischio:\n",
    "- 0 Vasi: La stragrande maggioranza √® sana.\n",
    "- 1, 2, 3 Vasi: La situazione si ribalta completamente. Avere anche solo un vaso colorato dalla fluoroscopia indica una probabilit√† altissima di malattia.\n",
    "\n",
    "- Correlazioni: La Heatmap conferma che ST depression, Exercise angina e Number of vessels sono i predittori positivi pi√π forti. Max HR √® il pi√π forte predittore negativo (pi√π alto √® il battito massimo, pi√π sano √® il cuore)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ecae6",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing & Feature Engineering\n",
    "(Gestione valori mancanti, encoding categoriche, scaling, creazione nuove feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Data Preprocessing & Feature Engineering\n",
    "\n",
    "# --- 3.1 Feature Creation Function ---\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['Cholesterol_Age_Ratio'] = df['Cholesterol'] / df['Age']\n",
    "    \n",
    "    df['Age_MaxHR_Interaction'] = df['Age'] * df['Max HR']\n",
    "\n",
    "    df['Hemodynamic_Risk'] = df['Age'] * df['BP']\n",
    "    \n",
    "    df['Severe_Angina'] = ((df['Chest pain type'] == 4) & (df['Exercise angina'] == 1)).astype(int)\n",
    "\n",
    "    df['Angina_Thallium_Combo'] = df['Exercise angina'] * df['Thallium']\n",
    "    \n",
    "    df['ST_Heart_Stress'] = df['ST depression'] * df['Slope of ST']\n",
    "    \n",
    "    df['Age_Group'] = pd.cut(df['Age'], bins=[0, 45, 60, 100], labels=[0, 1, 2]).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_eng = create_features(train)\n",
    "test_eng = create_features(test)\n",
    "\n",
    "print(\"‚úÖ Feature Engineering completato. Nuove colonne create.\")\n",
    "display(train_eng[['Cholesterol_Age_Ratio', 'Age_MaxHR_Interaction', 'Hemodynamic_Risk', \n",
    "                   'Severe_Angina', 'Angina_Thallium_Combo', 'ST_Heart_Stress', 'Age_Group']].head(4))\n",
    "\n",
    "# --- 3.2 Preprocessing Pipeline Setup ---\n",
    "\n",
    "target_col = 'Heart Disease'\n",
    "\n",
    "categorical_features = [\n",
    "    'Sex', 'Chest pain type', 'FBS over 120', 'EKG results', \n",
    "    'Exercise angina', 'Slope of ST', 'Thallium', \n",
    "    'Age_Group', 'Severe_Angina' \n",
    "]\n",
    "\n",
    "numeric_features = [\n",
    "    col for col in train_eng.columns \n",
    "    if col not in categorical_features + ['id', target_col]\n",
    "]\n",
    "\n",
    "print(f\"\\nüî¢ Feature Numeriche ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"üî† Feature Categoriche ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), \n",
    "    ('scaler', StandardScaler()) \n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)) \n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    verbose_feature_names_out=False \n",
    ")\n",
    "\n",
    "preprocessor.set_output(transform='pandas')\n",
    "\n",
    "X = train_eng.drop(columns=['id', target_col])\n",
    "y = train_eng[target_col]\n",
    "\n",
    "X_test = test_eng.drop(columns=['id']) \n",
    "test_ids = test_eng['id']\n",
    "\n",
    "print(\"\\n‚öôÔ∏è Preprocessor configurato.\")\n",
    "print(f\"‚úÖ Dati pronti: X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "new_feats = ['Cholesterol_Age_Ratio', 'Age_MaxHR_Interaction', 'Hemodynamic_Risk', \n",
    "             'Severe_Angina', 'Angina_Thallium_Combo', 'ST_Heart_Stress']\n",
    "print(\"\\nüìä Correlazione Nuove Feature con il Target:\")\n",
    "print(train_eng[new_feats + [target_col]].corr()[target_col].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a81d5f",
   "metadata": {},
   "source": [
    "## 4. Hardware-Aware Model Definition & Selection\n",
    "(Definizione modelli adattiva: GPU per Kaggle, CPU Ottimizzata per Mac/PC, pipeline e strategia di validazione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fbf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Model Selection & Evaluation Strategy\n",
    "\n",
    "# --- 4.1 Model Definitions ---\n",
    "\n",
    "import shutil\n",
    "\n",
    "HAS_NVIDIA_GPU = shutil.which('nvidia-smi') is not None\n",
    "IS_KAGGLE = os.getenv('KAGGLE_KERNEL_RUN_TYPE') is not None\n",
    "\n",
    "print(f\"‚öôÔ∏è Hardware Detection: {'‚úÖ GPU NVIDIA Trovata (Mode: FAST)' if HAS_NVIDIA_GPU else 'üíª GPU NVIDIA non trovata (Mode: CPU Compatibility)'}\")\n",
    "\n",
    "if HAS_NVIDIA_GPU:\n",
    "    print(\"üöÄ Configurazione GPU Attiva (CUDA)\")\n",
    "    xgb_params = {\n",
    "        'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6,\n",
    "        'subsample': 0.8, 'colsample_bytree': 0.8, 'random_state': RANDOM_STATE,\n",
    "        'eval_metric': 'auc', 'device': 'cuda', 'tree_method': 'hist'\n",
    "    }\n",
    "    lgbm_params = {\n",
    "        'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31,\n",
    "        'random_state': RANDOM_STATE, 'verbose': -1, 'device': 'gpu'\n",
    "    }\n",
    "    cat_params = {\n",
    "        'iterations': 1000, 'learning_rate': 0.05, 'depth': 6,\n",
    "        'random_seed': RANDOM_STATE, 'verbose': 0, 'allow_writing_files': False,\n",
    "        'task_type': 'GPU', 'devices': '0'\n",
    "    }\n",
    "    CV_N_JOBS = 1\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Configurazione CPU (Compatibilit√† Mac/PC)\")\n",
    "    \n",
    "    xgb_params = {\n",
    "        'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6,\n",
    "        'subsample': 0.8, 'colsample_bytree': 0.8, 'random_state': RANDOM_STATE,\n",
    "        'eval_metric': 'auc',\n",
    "        'n_jobs': 4 \n",
    "    }\n",
    "    lgbm_params = {\n",
    "        'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31,\n",
    "        'random_state': RANDOM_STATE, 'verbose': -1,\n",
    "        'n_jobs': 4\n",
    "    }\n",
    "    cat_params = {\n",
    "        'iterations': 1000, 'learning_rate': 0.05, 'depth': 6,\n",
    "        'random_seed': RANDOM_STATE, 'verbose': 0,\n",
    "        'allow_writing_files': False, \n",
    "        'loss_function': 'Logloss',  \n",
    "        'eval_metric': 'AUC' \n",
    "    }\n",
    "    CV_N_JOBS = 1\n",
    "\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(**xgb_params),\n",
    "    'LightGBM': LGBMClassifier(**lgbm_params),\n",
    "    'CatBoost': CatBoostClassifier(**cat_params) \n",
    "}\n",
    "\n",
    "# --- 4.2 Cross-Validation Function ---\n",
    "\n",
    "def evaluate_models(models, X, y, preprocessor):\n",
    "    results = {}\n",
    "    print(f\"\\nüöÄ Inizio Training su {len(X)} righe con {N_FOLDS}-Fold CV...\")\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        \n",
    "        try:\n",
    "            scores = cross_val_score(pipeline, X, y, cv=cv, scoring='roc_auc', n_jobs=CV_N_JOBS, error_score='raise')\n",
    "            mean_score = np.mean(scores)\n",
    "            print(f\"‚úÖ {name:10} | ROC-AUC: {mean_score:.5f} (+/- {np.std(scores):.5f})\")\n",
    "            results[name] = mean_score\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {name:10} | ERRORE: {e}\")\n",
    "            results[name] = 0 \n",
    "        \n",
    "    return results\n",
    "\n",
    "# --- 4.3 Execute Evaluation ---\n",
    "model_scores = evaluate_models(models, X, y, preprocessor)\n",
    "best_model_name = max(model_scores, key=model_scores.get)\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name} con AUC: {model_scores[best_model_name]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84711f0",
   "metadata": {},
   "source": [
    "## 5. Ensemble Construction & Training\n",
    "(Creazione del Voting Classifier e configurazione dell'addestramento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced0c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Ensemble & Final Training\n",
    "\n",
    "print(\"ü§ù Costruzione dell'Ensemble (XGBoost + LightGBM + CatBoost)...\")\n",
    "\n",
    "successful_models = [name for name, score in model_scores.items() if score > 0.5]\n",
    "\n",
    "if not successful_models:\n",
    "    raise ValueError(\"‚ùå Nessun modello valido trovato! Controlla gli errori sopra.\")\n",
    "\n",
    "estimators_list = []\n",
    "print(f\"Modelli inclusi nell'Ensemble: {successful_models}\")\n",
    "\n",
    "if 'XGBoost' in successful_models:\n",
    "    estimators_list.append(('xgb', Pipeline(steps=[('preprocessor', preprocessor), ('model', XGBClassifier(**xgb_params))])))\n",
    "if 'LightGBM' in successful_models:\n",
    "    estimators_list.append(('lgbm', Pipeline(steps=[('preprocessor', preprocessor), ('model', LGBMClassifier(**lgbm_params))])))\n",
    "if 'CatBoost' in successful_models:\n",
    "    estimators_list.append(('cat', Pipeline(steps=[('preprocessor', preprocessor), ('model', CatBoostClassifier(**cat_params))])))\n",
    "\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=estimators_list,\n",
    "    voting='soft',\n",
    "    n_jobs=1 \n",
    ")\n",
    "\n",
    "print(f\"üöÄ Validazione Ensemble ({len(estimators_list)} modelli)...\")\n",
    "ensemble_scores = cross_val_score(ensemble_model, X, y, cv=10, scoring='roc_auc', n_jobs=CV_N_JOBS)\n",
    "\n",
    "mean_ens = np.mean(ensemble_scores)\n",
    "std_ens = np.std(ensemble_scores)\n",
    "\n",
    "print(f\"üèÜ Ensemble ROC-AUC: {mean_ens:.5f} (+/- {std_ens:.5f})\")\n",
    "\n",
    "print(\"\\nüí™ Addestramento finale sul 100% dei dati di Train...\")\n",
    "ensemble_model.fit(X, y)\n",
    "print(\"‚úÖ Training completato.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1ef6d",
   "metadata": {},
   "source": [
    "## 6. Model Diagnostics & Visual Evaluation\n",
    "(Analisi approfondita: Curve ROC, Matrice di Confusione e Report di Classificazione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aca2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Model Diagnostics & Visual Evaluation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "print(\"üîç Esecuzione Diagnostica (questo potrebbe richiedere un attimo)...\")\n",
    "\n",
    "y_train_pred_proba = cross_val_predict(ensemble_model, X, y, cv=10, method='predict_proba', n_jobs=4)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y, y_train_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# --- A. ROC Curve (Plotly) ---\n",
    "fig_roc = px.area(\n",
    "    x=fpr, y=tpr,\n",
    "    title=f'ROC Curve (AUC = {roc_auc:.4f})',\n",
    "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
    "    width=700, height=600\n",
    ")\n",
    "fig_roc.add_shape(\n",
    "    type='line', line=dict(dash='dash'),\n",
    "    x0=0, x1=1, y0=0, y1=1\n",
    ")\n",
    "fig_roc.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig_roc.update_xaxes(constrain='domain')\n",
    "fig_roc.show()\n",
    "\n",
    "# --- B. Confusion Matrix ---\n",
    "threshold = 0.5\n",
    "y_train_pred_class = (y_train_pred_proba > threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y, y_train_pred_class)\n",
    "\n",
    "z = cm\n",
    "x = ['Predicted Healthy', 'Predicted Disease']\n",
    "y_labels = ['Actual Healthy', 'Actual Disease']\n",
    "\n",
    "# Standard sklearn:\n",
    "# [[TN, FP],\n",
    "#  [FN, TP]]\n",
    "\n",
    "fig_cm = ff.create_annotated_heatmap(\n",
    "    z, x=x, y=y_labels, colorscale='Blues', showscale=True\n",
    ")\n",
    "fig_cm.update_layout(title_text='Confusion Matrix (Threshold = 0.5)', width=600, height=500)\n",
    "fig_cm.show()\n",
    "\n",
    "# --- C. Classification Report ---\n",
    "print(\"\\nüìù Report di Classificazione Dettagliato:\")\n",
    "print(classification_report(y, y_train_pred_class, target_names=['Healthy', 'Disease']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbb58f",
   "metadata": {},
   "source": [
    "## 7. Final Prediction & Submission\n",
    "(Inferenza sul Test Set, check della distribuzione e creazione CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Final Prediction & Submission\n",
    "\n",
    "# --- 7.1 Prediction on Test Set ---\n",
    "print(\"üîÆ Generazione predizioni sul Test Set...\")\n",
    "\n",
    "y_pred_probs = ensemble_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# --- 7.2 Submission DataFrame Creation ---\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Heart Disease': y_pred_probs\n",
    "})\n",
    "\n",
    "print(\"\\n--- Anteprima Submission ---\")\n",
    "display(submission.head())\n",
    "\n",
    "fig = px.histogram(submission, x='Heart Disease', nbins=50, title='Distribuzione Probabilit√† Predette (Test Set)')\n",
    "fig.show()\n",
    "\n",
    "# --- 7.3 Save to CSV ---\n",
    "file_name = 'submission.csv'\n",
    "submission.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"‚úÖ File salvato: {file_name}\")\n",
    "print(f\"Dimensione file: {submission.shape}\")\n",
    "\n",
    "from IPython.display import FileLink\n",
    "FileLink(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
